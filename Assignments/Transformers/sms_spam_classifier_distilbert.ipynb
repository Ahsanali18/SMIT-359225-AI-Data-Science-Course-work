{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8dfb870caf14449bd5a0e9b230c8255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2e7d2945dcb4cb4a5cfd7ed7e19c36a",
              "IPY_MODEL_b0da681b6cc64c01b16cbaa115e866af",
              "IPY_MODEL_11535a940d894a6695131b78cd70f821"
            ],
            "layout": "IPY_MODEL_0ed3dd9cbb3c44c08ef6c25bd10db1d8"
          }
        },
        "d2e7d2945dcb4cb4a5cfd7ed7e19c36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ad02e2dc5b949889fda5458c525facd",
            "placeholder": "​",
            "style": "IPY_MODEL_052125280a32460db4e6bdfe65536087",
            "value": "Map: 100%"
          }
        },
        "b0da681b6cc64c01b16cbaa115e866af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7200e51c948485cbfd7643191cacb4e",
            "max": 5574,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fbac3b08b434c8eb133dc9b469cfecf",
            "value": 5574
          }
        },
        "11535a940d894a6695131b78cd70f821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c43d35d5a9bc4da8aaf9011513cd94dd",
            "placeholder": "​",
            "style": "IPY_MODEL_42e46ae1167b46428171686c24a091a4",
            "value": " 5574/5574 [00:01&lt;00:00, 3657.54 examples/s]"
          }
        },
        "0ed3dd9cbb3c44c08ef6c25bd10db1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad02e2dc5b949889fda5458c525facd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052125280a32460db4e6bdfe65536087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7200e51c948485cbfd7643191cacb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fbac3b08b434c8eb133dc9b469cfecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c43d35d5a9bc4da8aaf9011513cd94dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e46ae1167b46428171686c24a091a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b8dfb870caf14449bd5a0e9b230c8255",
            "d2e7d2945dcb4cb4a5cfd7ed7e19c36a",
            "b0da681b6cc64c01b16cbaa115e866af",
            "11535a940d894a6695131b78cd70f821",
            "0ed3dd9cbb3c44c08ef6c25bd10db1d8",
            "9ad02e2dc5b949889fda5458c525facd",
            "052125280a32460db4e6bdfe65536087",
            "d7200e51c948485cbfd7643191cacb4e",
            "6fbac3b08b434c8eb133dc9b469cfecf",
            "c43d35d5a9bc4da8aaf9011513cd94dd",
            "42e46ae1167b46428171686c24a091a4"
          ]
        },
        "id": "_ohYmfCU-B0O",
        "outputId": "eeddd7a8-f4b5-4dd5-eaed-f09a1651ffd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SMS Spam Dataset...\n",
            "\n",
            "=== Dataset Info ===\n",
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sms', 'label'],\n",
            "        num_rows: 5574\n",
            "    })\n",
            "})\n",
            "\n",
            "Column names: ['sms', 'label']\n",
            "Number of samples: 5574\n",
            "\n",
            "=== Sample Data ===\n",
            "Example 1:\n",
            "  Text: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "  Label: 0\n",
            "Example 2:\n",
            "  Text: Ok lar... Joking wif u oni...\n",
            "\n",
            "  Label: 0\n",
            "Example 3:\n",
            "  Text: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n",
            "  Label: 1\n",
            "\n",
            "=== Label Mapping ===\n",
            "Label map (ID → Name): {0: 'ham', 1: 'spam'}\n",
            "ID map (Name → ID): {'ham': 0, 'spam': 1}\n",
            "\n",
            "=== Loading Tokenizer ===\n",
            "Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5574 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8dfb870caf14449bd5a0e9b230c8255"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Preparing Train/Eval Split ===\n",
            "Total dataset size: 5574\n",
            "Using 4459 samples for training and 1000 for evaluation\n",
            "Training samples: 4459\n",
            "Evaluation samples: 1000\n",
            "\n",
            "=== Loading Model ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Training ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [558/558 01:59, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.026105</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.974790</td>\n",
              "      <td>0.983051</td>\n",
              "      <td>0.978903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>0.028424</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.974576</td>\n",
              "      <td>0.966387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Final Evaluation ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.02610485814511776, 'eval_accuracy': 0.995, 'eval_precision': 0.9747899159663865, 'eval_recall': 0.9830508474576272, 'eval_f1': 0.9789029535864979, 'eval_runtime': 3.5367, 'eval_samples_per_second': 282.75, 'eval_steps_per_second': 17.813, 'epoch': 2.0}\n",
            "\n",
            "=== Saving Model ===\n",
            "Model and tokenizer saved to './spam_model'\n",
            "\n",
            "=== Loading Saved Model for Inference ===\n",
            "\n",
            "=== Testing Predictions ===\n",
            "\n",
            "Text: 'Congratulations! You've won a free ticket.'\n",
            "Prediction: HAM\n",
            "Confidence: 0.9967\n",
            "Probabilities: Ham=0.9967, Spam=0.0033\n",
            "\n",
            "Text: 'Hey, are we meeting tomorrow?'\n",
            "Prediction: HAM\n",
            "Confidence: 0.9984\n",
            "Probabilities: Ham=0.9984, Spam=0.0016\n",
            "\n",
            "Text: 'URGENT! You have won $1000000! Click here NOW!'\n",
            "Prediction: SPAM\n",
            "Confidence: 0.9926\n",
            "Probabilities: Ham=0.0074, Spam=0.9926\n",
            "\n",
            "Text: 'Can you pick up some milk on your way home?'\n",
            "Prediction: HAM\n",
            "Confidence: 0.9979\n",
            "Probabilities: Ham=0.9979, Spam=0.0021\n",
            "\n",
            "Text: 'FREE entry to win a brand new iPhone! Text WIN to 12345'\n",
            "Prediction: SPAM\n",
            "Confidence: 0.9948\n",
            "Probabilities: Ham=0.0052, Spam=0.9948\n",
            "\n",
            "Text: 'Meeting scheduled for 3pm in conference room B'\n",
            "Prediction: HAM\n",
            "Confidence: 0.9831\n",
            "Probabilities: Ham=0.9831, Spam=0.0169\n",
            "\n",
            "=== Training Complete! ===\n",
            "Your spam classifier is ready to use!\n",
            "\n",
            "To use it later:\n",
            "1. Load the model: AutoModelForSequenceClassification.from_pretrained('./spam_model')\n",
            "2. Load the tokenizer: AutoTokenizer.from_pretrained('./spam_model')\n",
            "3. Use predict_with_label(text) function for predictions\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "SMS Spam Classifier using DistilBERT\n",
        "A complete implementation for fine-tuning a transformer model on spam detection\n",
        "\"\"\"\n",
        "\n",
        "# Disable wandb to avoid login prompts\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# Step 1: Explore the Dataset\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Loading SMS Spam Dataset...\")\n",
        "dataset = load_dataset(\"sms_spam\")\n",
        "\n",
        "print(\"\\n=== Dataset Info ===\")\n",
        "print(f\"Dataset structure: {dataset}\")\n",
        "print(f\"\\nColumn names: {dataset['train'].column_names}\")\n",
        "print(f\"Number of samples: {len(dataset['train'])}\")\n",
        "\n",
        "# Check first few examples\n",
        "print(\"\\n=== Sample Data ===\")\n",
        "for i in range(3):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"  Text: {dataset['train'][i]['sms']}\")\n",
        "    print(f\"  Label: {dataset['train'][i]['label']}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Step 2: Create Label Dictionary\n",
        "# ============================================================================\n",
        "\n",
        "label_map = {0: 'ham', 1: 'spam'}\n",
        "id_map = {'ham': 0, 'spam': 1}\n",
        "\n",
        "print(\"\\n=== Label Mapping ===\")\n",
        "print(f\"Label map (ID → Name): {label_map}\")\n",
        "print(f\"ID map (Name → ID): {id_map}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Step 3: Tokenize and Preprocess\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Loading Tokenizer ===\")\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text with padding and truncation\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['sms'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# ============================================================================\n",
        "# Step 4: Split Train & Evaluation Data\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Preparing Train/Eval Split ===\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "shuffled_dataset = tokenized_dataset['train'].shuffle(seed=42)\n",
        "\n",
        "# Get total dataset size\n",
        "total_size = len(shuffled_dataset)\n",
        "print(f\"Total dataset size: {total_size}\")\n",
        "\n",
        "# Adapt split based on available data\n",
        "# Use 80% for training and 20% for evaluation (or max 5000/1000 if available)\n",
        "train_size = min(5000, int(total_size * 0.8))\n",
        "eval_size = min(1000, total_size - train_size)\n",
        "\n",
        "print(f\"Using {train_size} samples for training and {eval_size} for evaluation\")\n",
        "\n",
        "# Split into train and eval\n",
        "train_dataset = shuffled_dataset.select(range(train_size))\n",
        "eval_dataset = shuffled_dataset.select(range(train_size, train_size + eval_size))\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Evaluation samples: {len(eval_dataset)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Step 5: Fine-Tune DistilBERT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Loading Model ===\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label=label_map,\n",
        "    label2id=id_map\n",
        ")\n",
        "\n",
        "# Define metrics computation\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"Calculate accuracy, precision, recall, and F1 score\"\"\"\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Starting Training ===\")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n=== Final Evaluation ===\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {eval_results}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Step 6: Save Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Saving Model ===\")\n",
        "trainer.save_model(\"./spam_model\")\n",
        "tokenizer.save_pretrained(\"./spam_model\")\n",
        "print(\"Model and tokenizer saved to './spam_model'\")\n",
        "\n",
        "# ============================================================================\n",
        "# Step 7: Load Model & Make Predictions\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Loading Saved Model for Inference ===\")\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(\"./spam_model\")\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"./spam_model\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "def predict_with_label(text):\n",
        "    \"\"\"\n",
        "    Predict whether a text is spam or ham\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text message\n",
        "\n",
        "    Returns:\n",
        "        dict: Prediction results with label and confidence\n",
        "    \"\"\"\n",
        "    # Tokenize input\n",
        "    inputs = loaded_tokenizer(\n",
        "        text,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Move inputs to device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "        confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "    # Get label name\n",
        "    label_name = label_map[predicted_class]\n",
        "\n",
        "    return {\n",
        "        'text': text,\n",
        "        'label': label_name,\n",
        "        'confidence': f\"{confidence:.4f}\",\n",
        "        'probabilities': {\n",
        "            'ham': f\"{probabilities[0][0].item():.4f}\",\n",
        "            'spam': f\"{probabilities[0][1].item():.4f}\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# Test Examples\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Testing Predictions ===\")\n",
        "\n",
        "test_texts = [\n",
        "    \"Congratulations! You've won a free ticket.\",\n",
        "    \"Hey, are we meeting tomorrow?\",\n",
        "    \"URGENT! You have won $1000000! Click here NOW!\",\n",
        "    \"Can you pick up some milk on your way home?\",\n",
        "    \"FREE entry to win a brand new iPhone! Text WIN to 12345\",\n",
        "    \"Meeting scheduled for 3pm in conference room B\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    result = predict_with_label(text)\n",
        "    print(f\"\\nText: '{result['text']}'\")\n",
        "    print(f\"Prediction: {result['label'].upper()}\")\n",
        "    print(f\"Confidence: {result['confidence']}\")\n",
        "    print(f\"Probabilities: Ham={result['probabilities']['ham']}, Spam={result['probabilities']['spam']}\")\n",
        "\n",
        "print(\"\\n=== Training Complete! ===\")\n",
        "print(\"Your spam classifier is ready to use!\")\n",
        "print(\"\\nTo use it later:\")\n",
        "print(\"1. Load the model: AutoModelForSequenceClassification.from_pretrained('./spam_model')\")\n",
        "print(\"2. Load the tokenizer: AutoTokenizer.from_pretrained('./spam_model')\")\n",
        "print(\"3. Use predict_with_label(text) function for predictions\")"
      ]
    }
  ]
}